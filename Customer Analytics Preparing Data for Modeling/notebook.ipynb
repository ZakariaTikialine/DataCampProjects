{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648795d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# --- Load dataset (update path if needed) ---\n",
    "ds_jobs = pd.read_csv(\"customer_train.csv\")\n",
    "\n",
    "# keep original untouched for memory comparisons\n",
    "original = ds_jobs\n",
    "\n",
    "# --- Copy for transformation ---\n",
    "ds_jobs_transformed = ds_jobs.copy()\n",
    "\n",
    "# ---------------------------\n",
    "# Explicit: map job_change -> bool\n",
    "# ---------------------------\n",
    "def _to_bool_val(x):\n",
    "    if pd.isna(x):\n",
    "        return pd.NA\n",
    "    s = str(x).strip().lower()\n",
    "    if s in {\"1\", \"true\", \"yes\", \"y\", \"t\"}:\n",
    "        return True\n",
    "    if s in {\"0\", \"false\", \"no\", \"n\", \"f\"}:\n",
    "        return False\n",
    "    return pd.NA\n",
    "\n",
    "mapped = ds_jobs_transformed['job_change'].map(_to_bool_val)\n",
    "\n",
    "# if any NA remain, keep pandas nullable boolean dtype; else use plain bool\n",
    "if mapped.isna().any():\n",
    "    ds_jobs_transformed['job_change'] = mapped.astype('boolean')   # nullable boolean\n",
    "else:\n",
    "    ds_jobs_transformed['job_change'] = mapped.astype(bool)\n",
    "\n",
    "# ---------------------------\n",
    "# Convert columns with exactly two non-null unique values to boolean (skip job_change)\n",
    "# ---------------------------\n",
    "for col in ds_jobs_transformed.columns:\n",
    "    if col == 'job_change':\n",
    "        continue\n",
    "    # consider non-null uniques only (so that NaNs don't mask two-factor detection)\n",
    "    uniques = ds_jobs_transformed[col].dropna().unique()\n",
    "    if len(uniques) == 2:\n",
    "        # map common affirmative values to True when possible, otherwise map first->True, second->False\n",
    "        lower_uniques = [str(u).strip().lower() for u in uniques]\n",
    "        if any(u in {\"1\",\"true\",\"yes\",\"y\",\"t\"} for u in lower_uniques):\n",
    "            # map the one that looks like True -> True\n",
    "            true_val = uniques[lower_uniques.index(next(u for u in lower_uniques if u in {\"1\",\"true\",\"yes\",\"y\",\"t\"}))]\n",
    "            false_val = [u for u in uniques if u is not true_val][0]\n",
    "            ds_jobs_transformed[col] = ds_jobs_transformed[col].map({true_val: True, false_val: False}).astype('boolean' if ds_jobs_transformed[col].isna().any() else bool)\n",
    "        else:\n",
    "            # fallback: map first unique -> True, second -> False (keeps dtype boolean)\n",
    "            ds_jobs_transformed[col] = ds_jobs_transformed[col].map({uniques[0]: True, uniques[1]: False}).astype('boolean' if ds_jobs_transformed[col].isna().any() else bool)\n",
    "\n",
    "# ---------------------------\n",
    "# Integers -> int32\n",
    "# ---------------------------\n",
    "# If integer columns are float (e.g., have NaN), we skip automatic conversion here.\n",
    "int_cols = ds_jobs_transformed.select_dtypes(include=['int64']).columns.tolist()\n",
    "for col in int_cols:\n",
    "    ds_jobs_transformed[col] = ds_jobs_transformed[col].astype(np.int32)\n",
    "\n",
    "# ---------------------------\n",
    "# Floats -> float16\n",
    "# ---------------------------\n",
    "float_cols = ds_jobs_transformed.select_dtypes(include=['float64']).columns.tolist()\n",
    "for col in float_cols:\n",
    "    ds_jobs_transformed[col] = ds_jobs_transformed[col].astype(np.float16)\n",
    "\n",
    "# ---------------------------\n",
    "# Define ordinal categories (ordered) using CategoricalDtype\n",
    "# ---------------------------\n",
    "# EXPERIENCE: <1, 1..20, 21+\n",
    "exp_order = ['<1'] + [str(i) for i in range(1, 21)] + ['21+']\n",
    "exp_dtype = CategoricalDtype(categories=exp_order, ordered=True)\n",
    "# COMPANY SIZE\n",
    "size_order = ['<10','10-49','50-99','100-499','500-999','1000-4999','5000-9999','10000+']\n",
    "size_dtype = CategoricalDtype(categories=size_order, ordered=True)\n",
    "# ENROLLED UNIVERSITY\n",
    "uni_order = ['no_enrollment','Part time course','Full time course']\n",
    "uni_dtype = CategoricalDtype(categories=uni_order, ordered=True)\n",
    "# EDUCATION LEVEL (natural order)\n",
    "edu_order = ['Primary School','High School','Graduate','Masters','Phd']\n",
    "edu_dtype = CategoricalDtype(categories=edu_order, ordered=True)\n",
    "# LAST NEW JOB\n",
    "job_order = ['never','1','2','3','4','5+']\n",
    "job_dtype = CategoricalDtype(categories=job_order, ordered=True)\n",
    "\n",
    "# Normalize possible variants and set ordered categoricals (safe, using .astype after cleaning)\n",
    "# normalize experience string representation: unify '>20' -> '21+'\n",
    "ds_jobs_transformed['experience'] = (\n",
    "    ds_jobs_transformed['experience']\n",
    "    .replace({'>20': '21+'})\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# apply ordered dtypes if columns exist\n",
    "if 'experience' in ds_jobs_transformed.columns:\n",
    "    ds_jobs_transformed['experience'] = ds_jobs_transformed['experience'].astype(exp_dtype)\n",
    "if 'company_size' in ds_jobs_transformed.columns:\n",
    "    ds_jobs_transformed['company_size'] = ds_jobs_transformed['company_size'].astype(size_dtype)\n",
    "if 'enrolled_university' in ds_jobs_transformed.columns:\n",
    "    ds_jobs_transformed['enrolled_university'] = ds_jobs_transformed['enrolled_university'].astype(uni_dtype)\n",
    "if 'education_level' in ds_jobs_transformed.columns:\n",
    "    ds_jobs_transformed['education_level'] = ds_jobs_transformed['education_level'].astype(edu_dtype)\n",
    "if 'last_new_job' in ds_jobs_transformed.columns:\n",
    "    ds_jobs_transformed['last_new_job'] = ds_jobs_transformed['last_new_job'].astype(job_dtype)\n",
    "\n",
    "# ---------------------------\n",
    "# Nominal categories -> category (all object columns not in ordinals and not boolean)\n",
    "# ---------------------------\n",
    "ordinal_cols = {'experience','company_size','enrolled_university','education_level','last_new_job'}\n",
    "for col in ds_jobs_transformed.select_dtypes(include=['object']).columns:\n",
    "    if col in ordinal_cols:\n",
    "        continue\n",
    "    # skip job_change and any columns already converted to boolean\n",
    "    if col == 'job_change':\n",
    "        continue\n",
    "    ds_jobs_transformed[col] = ds_jobs_transformed[col].astype('category')\n",
    "\n",
    "# ---------------------------\n",
    "# Drop nulls only in filtering columns (experience, company_size)\n",
    "# ---------------------------\n",
    "ds_jobs_transformed = ds_jobs_transformed.dropna(subset=['experience', 'company_size'])\n",
    "\n",
    "# ---------------------------\n",
    "# Final filtering: keep only students with >=10 years experience and company size >= 1000 employees\n",
    "# ---------------------------\n",
    "ds_jobs_transformed = ds_jobs_transformed[\n",
    "    (ds_jobs_transformed['experience'] >= '10') &\n",
    "    (ds_jobs_transformed['company_size'] >= '1000-4999')\n",
    "].copy()\n",
    "\n",
    "# ---------------------------\n",
    "# Final: print memory usage and dtype summary\n",
    "# ---------------------------\n",
    "print(\"=== ORIGINAL (before transformations) ===\")\n",
    "print(original.info(memory_usage='deep'))\n",
    "print(\"\\n=== TRANSFORMED & FILTERED (ds_jobs_transformed) ===\")\n",
    "print(ds_jobs_transformed.info(memory_usage='deep'))\n",
    "\n",
    "# quick preview\n",
    "print(\"\\nPreview of transformed data (first 5 rows):\")\n",
    "print(ds_jobs_transformed.head().T)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
